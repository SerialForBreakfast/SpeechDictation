Critique and Extension of ADR-001: Live Transcription Strategy & Visual Feedback
for Addition of Secure Recording + Playback Feature
Date: 2025-12-06

------------------------------------------------------------------------
1. Strengths of the ADR as Written
------------------------------------------------------------------------

The ADR correctly outlines a clean, minimal mental model for handling
SFSpeechRecognizer streaming updates:

• Treat the recognizer’s result as authoritative.  
• Do not append or merge partials — replace them.  
• Maintain two buffers: committedTranscript (stable) and currentPartialTranscript (processing).  
• UI displays “committed + partial” with styling applied at render time.  

These choices directly avoid the most common failure modes in live
transcription pipelines:

• Duplicate phrases when partials revise themselves  
• Stale segments when relying on append-only storage  
• TimingData pollution due to incremental partial additions  
• Flicker or disappearance caused by ambiguous “partial vs final” rules  

The ADR’s framing of the recognizer as the single source of truth is
correct and should remain the core invariant.

------------------------------------------------------------------------
2. Gaps, Missing Details, and Areas to Strengthen
------------------------------------------------------------------------

Although the ADR is solid for *live UI transcription*, several aspects
must be clarified or expanded before adding the “secure on‑device recording
+ playback” feature.

----------------------------------------
2.1 Clarify “latest transcript”
----------------------------------------

The ADR says:

• If isFinal == false → replace partial with latest bestTranscription  
• If isFinal == true → append latest transcript to committedTranscript  

However, “latest transcript” is ambiguous. You must specify:

• For live UI use → bestTranscription.formattedString  
• For persistence → reconstruct a normalized transcript from segments  
  (bestTranscription.segments), because formattedString alone loses
  timing fidelity necessary for playback highlighting.

Recommendation:

Explicitly distinguish:
- UI-only string (formattedString)  
- Persisted string + persisted segments derived from segments[]

----------------------------------------
2.2 Segment Model Not Fully Specified
----------------------------------------

For secure playback, you need at minimum:

struct TranscriptSegment: Codable {
    let index: Int
    let text: String
    let startTime: TimeInterval
    let duration: TimeInterval
}

Open questions not addressed in ADR:

• How segment timestamps relate to audio file start time  
• How to handle recognizer corrections that change segment boundaries  
• How many segments we may store across long recordings  
• Whether to persist silence or filler segments  

The ADR should explicitly specify:
- segments come from the *final* bestTranscription  
- startTime/duration tied to audio recording start  
- transcript reconstructed at save-time, not incrementally  

----------------------------------------
2.3 Edge Cases Around Restart, Stop, Timeout
----------------------------------------

SFSpeechRecognizer restarts approximately every 60 seconds.  
The ADR says you should “keep committedTranscript,” but it does not
specify what to do about:

• Partial text in progress when timeout occurs  
• Partial in-flight when user taps Stop  
• Partial in-flight when recognizer errors  
• Backgrounding events  

Rule that should be added:

At ANY terminal event — stop, timeout, error, background transition —
1. Commit partial to committedTranscript  
2. Create final transcript + segments snapshot  
3. Persist them atomically  
4. Then tear down recognition session  

This prevents silent data loss.

----------------------------------------
2.4 Missing Concurrency / Threading Guarantees
----------------------------------------

The ADR must state where transcription buffers live and who mutates them.

Recommended addition:

All transcript state (committedTranscript, currentPartialTranscript,
segments) is owned by a TranscriptionSession actor.  
The UI receives immutable snapshots on MainActor.

This prevents UI + recognizer threads from mutating the same buffers.

----------------------------------------
2.5 Persistence Model and Versioning Not Defined
----------------------------------------

To support secure playback, define a RecordingSessionRecord:

struct RecordingSessionRecord: Codable {
    let id: UUID
    let createdAt: Date
    let audioFilePath: String
    let finalTranscript: String
    let segments: [TranscriptSegment]
    let schemaVersion: Int
}

The ADR should define this contract so playback logic is stable even if the
transcription engine evolves.

------------------------------------------------------------------------
3. Required ADR Extension: Secure Recording + Playback
------------------------------------------------------------------------

Right now the ADR handles *live transcription*.  
To support *secure on-device recording + playback*, you need a new section:

----------------------------------------
3.1 Audio Capture + Transcript Linkage
----------------------------------------

Decisions to add:

• Each recording session produces:  
  - one audio file (e.g., <session-id>.m4a)  
  - one RecordingSessionRecord with transcript + segments  

• File naming:
  audioFile = "<UUID>.m4a" under Application Support/Recordings/

• Transcript and segments are generated ONLY once:  
  at stopRecording → final snapshot, immutable thereafter.

Playback *never* re-runs speech recognition.

----------------------------------------
3.2 Secure Storage Requirements
----------------------------------------

Define baseline policy:

• All audio files and transcript/segment metadata stored in
  app-private directory.  
• Enable Data Protection:
  NSFileProtectionCompleteUnlessOpen (or NSFileProtectionComplete).  
• No cloud sync by default.  
• All persistent files must be written atomically.  
• Optional: full AES-GCM encryption via CryptoKit.  

This raises the ADR from “live transcription behavior” to
“security guarantees for stored recordings.”

----------------------------------------
3.3 Deletion + Lifecycle
----------------------------------------

Define strict rules:

• Deleting a recording deletes:  
  - audio file  
  - transcript JSON  
  - segment metadata  
• No soft-delete staging  
• No orphaned files allowed  
• If speech recognition permission revoked, existing recordings remain
  unless user requests purge

----------------------------------------
3.4 Playback Rules
----------------------------------------

Playback uses ONLY the immutable final snapshot:

• Display finalTranscript verbatim  
• No italics, no partials  
• For highlighting per-word:
  currentSegment = segments
      .last(where: startTime <= currentTime < startTime + duration)

Playback never involves:
- partial buffers  
- TimingData used during live transcription  
- incremental corrections  

This prevents regressions or inconsistent behavior.

------------------------------------------------------------------------
4. Recommended ADR Text Additions (Verbatim Suggestions)
------------------------------------------------------------------------

Below are direct text blocks you can paste into ADR‑001.

----------------------------------------
4.1 Add Under “Core Rules”
----------------------------------------

For live UI:
- Use result.bestTranscription.formattedString directly.

For persistence:
- Reconstruct a normalized final transcript string from
  result.bestTranscription.segments.
- Persist segments with text, startTime, duration relative to the start
  of the audio session.

----------------------------------------
4.2 Add a “Concurrency Model” Section
----------------------------------------

All transcript state is owned by a TranscriptionSession actor.
UI observes value snapshots delivered on MainActor.

No code outside the actor mutates committedTranscript,
currentPartialTranscript, or segments.

----------------------------------------
4.3 Add a “Recording & Playback Integration” Section
----------------------------------------

Each recording session produces:
- A secure on-device audio file (<session-id>.m4a)
- A RecordingSessionRecord containing:
  id
  createdAt
  audioFilePath
  finalTranscript
  segments[]
  schemaVersion

On stop:
- Commit partial
- Generate finalTranscript + segments from final recognizer result
- Persist the RecordingSessionRecord atomically

Playback uses only these persisted values.  
We do not run recognition on stored audio.

----------------------------------------
4.4 Add a “Security & Privacy” Section
----------------------------------------

All audio and transcript data remain fully on-device.

Files are stored under Application Support/Recordings/
with NSFileProtectionCompleteUnlessOpen.

No cloud sync or external transmission occurs without additional user
consent and a separate ADR.

Record deletions remove audio + transcript data atomically.

------------------------------------------------------------------------
5. Resulting Architecture Benefits
------------------------------------------------------------------------

After adding these sections, ADR‑001 fully supports the secure recording
playback feature:

• Live UI is deterministic (committed + partial).  
• Save-time snapshot is canonical, immutable, and clean.  
• Playback uses guaranteed-stable final data only.  
• Security expectations (storage, access, deletion) are explicit.  
• Concurrency pitfalls avoided via actor ownership.  
• The system easily supports highlighting, export, recall, and future
  schema changes.  

This revised ADR becomes a strong foundation for implementing
the secure audio recording + transcription + playback pipeline.
